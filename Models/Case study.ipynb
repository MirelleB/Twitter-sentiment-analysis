{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo foi aplicado os seguintes algoritmos: LogisticRegression, LinearSVC, MultinomialNB, RandomForestClassifier e a combinação de todos estes algoritmos (Ensemble). Será reaizado um estudo de caso para cada algoritmo para o problema de classifição de Twitters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro vamos começar carregando as blibiotecas principais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Mirellebueno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos importar nossa base de treinamento. Esta base foi obtida em:https://www.kaggle.com/leandrodoze/sentiment-analysis-in-portuguese É um dataset com 8.199 amostras de twitters na linguagem Português."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../Tweets_Mg.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos Separar os textos das classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets =dataset[\"Text\"].values\n",
    "target = dataset[\"Classificacao\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vem a parte que eu considero uma das mais importantes: A limpeza do dataset, afinal, garbage in garbage out!\n",
    "Basicamente, primeiro transformo o texto todo em minusculo e depois retiro alguns caracteres especiais que podem confundir nosso classificador.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Text'].str.lower()\n",
    "\n",
    "tweets=dataset['Text'].replace(['^a-zA-Z0-9ÀÁÂÃÄÅÇÈÉÊËÌÍÎÏÒÓÔÕÖÙÚÛÜÝàáâãäåçèéêëìíîïðòóôõöùúûüýÿ,!?\\'\\`\\.\\(\\)'],[\"\"],regex=True)\n",
    "tweets=dataset['Text'].replace(['INC[0-9]{7,}'],[\" <INCIDENTE> \"],regex=True)\n",
    "tweets=dataset['Text'].replace(['[+-]?\\d+(?:\\.\\d+)?'],[\" <NUMERO> \"],regex=True)\n",
    "tweets=dataset['Text'].replace(['!'],[\" ! \"],regex=True)\n",
    "tweets=dataset['Text'].replace(['\\('],[\" ( \"],regex=True)\n",
    "tweets=dataset['Text'].replace(['\\)'],[\" ) \"],regex=True)\n",
    "tweets=dataset['Text'].replace(['\\?'],[\" ? \"],regex=True)\n",
    "tweets=dataset['Text'].replace(['\\s{2,}'],[\" \"],regex=True)\n",
    "tweets=dataset['Text'].replace(\"..\",\"\")\n",
    "tweets=dataset['Text'].replace('\"', \"\")\n",
    "tweets=dataset['Text'].replace(\"''\", \"\")\n",
    "tweets=dataset['Text'].replace(\"p/\", \"\")\n",
    "tweets=dataset['Text'].replace(\"RT \", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainda nesta etapa de limpeza eu recupero todos os \"stop words\". Os stop words,assim como o nome já diz, são palavras de parada, como por exemplo \"de, a, em, entretanto\" e etc, eu prefiro tirar devido a trabalhos na literatura que demostram ganhos de performace com a retirada dos mesmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A próxima etapa, é de transformação de dados, que faz parte do pré-processamento. A transformação de dados neste problema que estamos tratando, é transformar as palavras em número e como fazemos isso? Transformamos as palavras em uma grande matriz/vetor de 0 e 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2),stop_words=stopwords)\n",
    "vectorizer.fit(tweets)\n",
    "\n",
    "X_tranform_vector = vectorizer.transform(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ngram_range Estou pedindo para que ele tranforme a cada duas palvras, por exemplo, a frase: Eu gosto de cachorro, nossa funçaõ irá mandar {eu gosto,de cachorro}. Esta decisão foi devido a relatos de ganhos de desempenho na literatura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Um dos motivos pela escolha dos modelos de Regressão lógica são por serem  mais faceis de interpretar e assim como os modelos lineares aprendem mais rapido e vem tendo resultados satisfatorios. Antes de o treinar definitivamente, devemos encontrar o melhor coeficiente de regularização, que nos traga mais ganhos, que neste caso por meio da acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.9323088181485547\n",
      "Accuracy for C=0.05: 0.9681668496158068\n",
      "Accuracy for C=0.25: 0.9904866447127698\n",
      "Accuracy for C=0.5: 0.995853152823515\n",
      "Accuracy for C=1: 0.9971947798512014\n"
     ]
    }
   ],
   "source": [
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lR = LogisticRegression(C=c)\n",
    "    lR.fit(X_tranform_vector, target)\n",
    "    print (\"Accuracy for C=%s: %s\"% (c, accuracy_score(target, lR.predict(X_tranform_vector))))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Melhor valor de C é 1. Vamos treinar nosso classificador com este valor."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_logistic_regression= LogisticRegression(C=1)\n",
    "model_logistic_regression.fit(X_tranform_vector, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a validação do nosso modelo, eu escolhi o método \"Cross Validation\". Acredito que seja um dos melhores métodos para avaliar a capacidade de generalização do modelo. Aqui eu dividi nosso dataset em 10 partições."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8934016343456519"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_validation = cross_val_predict(model_logistic_regression, X_tranform_vector , target, cv = 10)\n",
    "\n",
    "metrics.accuracy_score(target, result_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porém, devido ao fato de que a acurácia é problematica(ruidos,desbalanceamento etc..), precisamos ter uma visão geral dos erros do nosso classificador, para isso a função \"metrics.classification_report\" nos traz um detalhamento dos erros e também da matriz de confusão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'             precision    recall  f1-score   support\\n\\n   Positivo       0.96      0.88      0.92      3300\\n   Negativo       0.92      0.92      0.92      2446\\n     Neutro       0.80      0.88      0.84      2453\\n\\navg / total       0.90      0.89      0.89      8199\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.classification_report(target, result_validation, [\"Positivo\", \"Negativo\", \"Neutro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predito</th>\n",
       "      <th>Negativo</th>\n",
       "      <th>Neutro</th>\n",
       "      <th>Positivo</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negativo</th>\n",
       "      <td>2256</td>\n",
       "      <td>181</td>\n",
       "      <td>9</td>\n",
       "      <td>2446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutro</th>\n",
       "      <td>188</td>\n",
       "      <td>2161</td>\n",
       "      <td>104</td>\n",
       "      <td>2453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positivo</th>\n",
       "      <td>19</td>\n",
       "      <td>373</td>\n",
       "      <td>2908</td>\n",
       "      <td>3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>2463</td>\n",
       "      <td>2715</td>\n",
       "      <td>3021</td>\n",
       "      <td>8199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predito   Negativo  Neutro  Positivo   All\n",
       "Real                                      \n",
       "Negativo      2256     181         9  2446\n",
       "Neutro         188    2161       104  2453\n",
       "Positivo        19     373      2908  3300\n",
       "All           2463    2715      3021  8199"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(target, result_validation, rownames = [\"Real\"], colnames=[\"Predito\"], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora para a avaliação do nosso próximo modelo:  LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim como para o modelo Logist Regression, precisamos definir um valor para C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.9841444078546164\n",
      "Accuracy for C=0.05: 0.9962190511037932\n",
      "Accuracy for C=0.25: 0.9985364068788877\n",
      "Accuracy for C=0.5: 0.9986583729723137\n",
      "Accuracy for C=1: 0.9986583729723137\n"
     ]
    }
   ],
   "source": [
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    linearSVC_model = LinearSVC(C=c)\n",
    "    linearSVC_model.fit(X_tranform_vector, target)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(target, linearSVC_model.predict(X_tranform_vector))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os melhores valores de C são: 0.5 e 1. Ficaremos com o valor 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_linear_SVC= LinearSVC(C=0.5)\n",
    "model_linear_SVC.fit(X_tranform_vector, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8962068544944506"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_validation_model_linear_svc = cross_val_predict(model_linear_SVC, X_tranform_vector , target, cv = 10)\n",
    "\n",
    "metrics.accuracy_score(target, result_validation_model_linear_svc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'             precision    recall  f1-score   support\\n\\n   Positivo       0.97      0.87      0.91      3300\\n   Negativo       0.93      0.92      0.93      2446\\n     Neutro       0.79      0.91      0.85      2453\\n\\navg / total       0.90      0.90      0.90      8199\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metrics.classification_report(target, result_validation_model_linear_svc, [\"Positivo\", \"Negativo\", \"Neutro\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predito</th>\n",
       "      <th>Negativo</th>\n",
       "      <th>Neutro</th>\n",
       "      <th>Positivo</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negativo</th>\n",
       "      <td>2259</td>\n",
       "      <td>168</td>\n",
       "      <td>19</td>\n",
       "      <td>2446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutro</th>\n",
       "      <td>142</td>\n",
       "      <td>2233</td>\n",
       "      <td>78</td>\n",
       "      <td>2453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positivo</th>\n",
       "      <td>19</td>\n",
       "      <td>425</td>\n",
       "      <td>2856</td>\n",
       "      <td>3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>2420</td>\n",
       "      <td>2826</td>\n",
       "      <td>2953</td>\n",
       "      <td>8199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predito   Negativo  Neutro  Positivo   All\n",
       "Real                                      \n",
       "Negativo      2259     168        19  2446\n",
       "Neutro         142    2233        78  2453\n",
       "Positivo        19     425      2856  3300\n",
       "All           2420    2826      2953  8199"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(target, result_validation_model_linear_svc, rownames = [\"Real\"], colnames=[\"Predito\"], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos repetir o mesmo processo para o classificador: MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_multinomialNB = MultinomialNB()\n",
    "model_multinomialNB.fit(X_tranform_vector, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8963288205878766"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_validation_model_MultinomialNB = cross_val_predict(model_multinomialNB, X_tranform_vector , target, cv = 10)\n",
    "\n",
    "metrics.accuracy_score(target, result_validation_model_MultinomialNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'             precision    recall  f1-score   support\\n\\n   Positivo       0.97      0.87      0.92      3300\\n   Negativo       0.90      0.94      0.92      2446\\n     Neutro       0.81      0.89      0.85      2453\\n\\navg / total       0.90      0.90      0.90      8199\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metrics.classification_report(target, result_validation_model_MultinomialNB, [\"Positivo\", \"Negativo\", \"Neutro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
